{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input\n",
    "from keras.layers import Reshape\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling2D\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers.core import Flatten\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras import initializers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def dataInit():\n",
    "    print('Loading the data')\n",
    "    (X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "    X_train = np.concatenate((X_train, X_test), axis=0)\n",
    "    X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "    print('Training Data: ', X_train.shape)\n",
    "    npRandom = np.random.RandomState(18)\n",
    "    X_noise = []\n",
    "    for i in range(X_train.shape[0]):\n",
    "        randomNoise = npRandom.uniform(-1,1,100)\n",
    "        X_noise.append(randomNoise)\n",
    "    X_noise = np.array(X_noise)\n",
    "    print('Random Noise Data: ', X_noise.shape)\n",
    "    return X_train, X_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def saveImage(imageData, imageName, epoch):\n",
    "    f, ax = plt.subplots(16, 8)\n",
    "    k = 0\n",
    "    for i in range(16):\n",
    "        for j in range(8):\n",
    "            pltImage = imageData[k][0]\n",
    "            ax[i,j].imshow(pltImage, interpolation='nearest',cmap='gray_r')\n",
    "            ax[i,j].axis('off')\n",
    "            k = k+1\n",
    "    f.set_size_inches(18.5, 10.5)\n",
    "    f.savefig('images/'+imageName+'_after_'+str(epoch)+'_epoch.png', dpi = 100, bbox_inches='tight', pad_inches = 0)\n",
    "    plt.close(f)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def initNormal(shape, name=None):\n",
    "    return initializers.normal(shape, scale=0.02, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data\n",
      "Training Data:  (70000, 28, 28)\n",
      "Random Noise Data:  (70000, 100)\n",
      "Number of examples:  70000\n",
      "Number of Batches:  546\n",
      "Number of epochs:  200\n",
      "Generator Model\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "initNormal() missing 1 required positional argument: 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-5bc670a186fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mReshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: initNormal() missing 1 required positional argument: 'shape'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    batchSize = 128\n",
    "    nbEpoch = 200\n",
    "    decayIter = 100\n",
    "    lr = 0.0002\n",
    "\n",
    "    X_train, X_noise = dataInit()\n",
    "    X_train = X_train[:, np.newaxis, :, :]\n",
    "    numExamples = (X_train.shape)[0]\n",
    "    numBatches = int(numExamples/float(batchSize))\n",
    "\n",
    "    print('Number of examples: ', numExamples)\n",
    "    print('Number of Batches: ', numBatches)\n",
    "    print('Number of epochs: ', nbEpoch)\n",
    "\n",
    "    adam=Adam(lr=lr, beta_1=0.5 )\n",
    "\n",
    "    print('Generator Model')\n",
    "\n",
    "    generator = Sequential()\n",
    "    generator.add(Dense( input_dim=100, output_dim=(128*7*7), init=initNormal()))\n",
    "    generator.add(Activation('relu'))\n",
    "    generator.add(Reshape((128, 7, 7)))\t\n",
    "    generator.add(UpSampling2D(size=(2, 2)))\n",
    "    generator.add(Convolution2D(64, 5, 5, border_mode='same'))\n",
    "    generator.add(Activation('relu'))\n",
    "    generator.add(UpSampling2D(size=(2, 2)))\n",
    "    generator.add(Convolution2D(1, 5, 5, border_mode='same'))\n",
    "    generator.add(Activation('tanh'))\n",
    "    generator.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "    print('Discriminator Model')\n",
    "\n",
    "    discriminator = Sequential()\n",
    "    discriminator.add(Convolution2D(64, 5, 5, border_mode='same', subsample=(2,2), input_shape=(1,28,28), init=initNormal))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    discriminator.add(Convolution2D(128, 5, 5, border_mode='same', subsample=(2,2)))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    discriminator.add(Flatten())\n",
    "    discriminator.add(Dense(1))\n",
    "    discriminator.add(Activation('sigmoid'))\n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "    discriminator.trainable = False\n",
    "\n",
    "    print('DCGAN model')\n",
    "\n",
    "    dcganInput = Input(shape=(100,))\n",
    "    x = generator(dcganInput)\n",
    "    dcganOutput = discriminator(x)\n",
    "    dcgan = Model(input=dcganInput, output=dcganOutput)\n",
    "    dcgan.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "    discriminator.trainable = True\n",
    "\n",
    "    if not os.path.exists('images'):\n",
    "        os.makedirs('images')\n",
    "    if not os.path.exists('models'):\n",
    "        os.makedirs('models')\n",
    "    if not os.path.exists('metrics'):\n",
    "        os.makedirs('metrics')\n",
    "\n",
    "    dLoss = []\n",
    "    gLoss = []\n",
    "\n",
    "    for epoch in range(1, nbEpoch + 1):\n",
    "        print('Epoch: ', epoch)\n",
    "\n",
    "        for i in range(numBatches):\n",
    "            noisePredictBatch = X_noise[np.random.randint(numExamples, size = batchSize)]\n",
    "            noiseDataBatch = generator.predict(noisePredictBatch)\n",
    "            origDataBatch = X_train[np.random.randint(numExamples, size = batchSize)]\n",
    "            noiseLabelsBatch, origLabelsBatch = np.zeros(batchSize).astype(int), np.ones(batchSize).astype(int)\n",
    "            trainBatch = np.concatenate((noiseDataBatch, origDataBatch), axis = 0)\n",
    "            trainLabels = np.concatenate((noiseLabelsBatch, origLabelsBatch))\n",
    "            trainBatch, trainLabels = shuffle(trainBatch, trainLabels)\n",
    "            discriminatorLoss = discriminator.train_on_batch(trainBatch, trainLabels)\n",
    "            dcganLabels = np.ones(batchSize).astype(int)\n",
    "            discriminator.trainable = False\n",
    "            dcganLoss = dcgan.train_on_batch(noisePredictBatch, dcganLabels)\n",
    "            discriminator.trainable = True\n",
    "\n",
    "        dLoss.append(discriminatorLoss)\n",
    "        gLoss.append(dcganLoss)\n",
    "\n",
    "        if (epoch % 5 == 0) or (epoch == 1):\n",
    "            saveImage(noiseDataBatch, 'generated', epoch)\n",
    "            print('after epoch: ', epoch)\n",
    "            print ('dcgan Loss: ', dcganLoss, '\\t discriminator loss', discriminatorLoss)\n",
    "            generator.save('models/generator_'+str(epoch)+'.h5')\n",
    "\n",
    "        if epoch > decayIter :\n",
    "            lrD = discriminator.optimizer.lr.get_value()\n",
    "            lrG = generator.optimizer.lr.get_value()\n",
    "            discriminator.optimizer.lr.set_value((lrD - lr/decayIter).astype(np.float32))\n",
    "            generator.optimizer.lr.set_value((lrG - lr/decayIter).astype(np.float32))\n",
    "            print('learning rate linearly decayed')\n",
    "\n",
    "    np.save('metrics/dLoss.npy', np.array(dLoss))\n",
    "    np.save('metrics/gLoss.npy', np.array(gLoss))\n",
    "    print('Peace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
